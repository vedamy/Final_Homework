{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00161330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e794117",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.\tWhat is inductive reasoning? Deductive reasoning? Give an example of each, different from the examples given in class. \n",
    "\n",
    "Using ONE of the following sources, complete the questions for only that source. \n",
    "\n",
    "Credit approval: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29\n",
    "\n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "\n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone - this one is a bit harder since it’s not binary like the others, but if you really want to master these concepts, you should pick this one. Use RMSE as a performance metric if you do this as regression. You should target a value of under 3.\n",
    "\n",
    "Note: at least one of your models should have the most relevant performance metric above .90 . All performance metrics should be above .75 . You will partially be graded on model performance.\n",
    "\n",
    "2.\tPreprocess your dataset. Indicate which steps worked and which didn’t. Include your thoughts on why certain steps worked and certain steps didn’t. \n",
    "\n",
    "3.\tCreate a decision tree model tuned to the best of your abilities. Explain how you tuned it.\n",
    "\n",
    "4.\tCreate a random forest model tuned to the best of your abilities. Explain how you tuned it.\n",
    "\n",
    "5.\tCreate an xgboost model tuned to the best of your abilities. Explain how you tuned it. \n",
    "\n",
    "6.\tWhich model performed best? What is your performance metric? Why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437f305",
   "metadata": {},
   "source": [
    "The dataset consists of 14 feature variables and 1 class label that determine the loan approval decision.\n",
    "All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.\n",
    "We do not even have the features names but we know the data has continuous or categorical columns. Based on that \n",
    "we can similarly label which columns are continuous (N), categorical (C) and if they require further encoding as\n",
    "(C_enc) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd2f1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#  Import SK-Learn Library\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error, r2_score , classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8c3efad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>C4_enc</th>\n",
       "      <th>C5_enc</th>\n",
       "      <th>C6_enc</th>\n",
       "      <th>N7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>N10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12_enc</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C1     N2      N3  C4_enc  C5_enc  C6_enc     N7  C8  C9  N10  C11  \\\n",
       "0     1  22.08  11.460       2       4       4  1.585   0   0    0    1   \n",
       "1     0  22.67   7.000       2       8       4  0.165   0   0    0    0   \n",
       "2     0  29.58   1.750       1       4       4  1.250   0   0    0    1   \n",
       "3     0  21.67  11.500       1       5       3  0.000   1   1   11    1   \n",
       "4     1  20.17   8.170       2       6       4  1.960   1   1   14    0   \n",
       "..   ..    ...     ...     ...     ...     ...    ...  ..  ..  ...  ...   \n",
       "685   1  31.57  10.500       2      14       4  6.500   1   0    0    0   \n",
       "686   1  20.67   0.415       2       8       4  0.125   0   0    0    0   \n",
       "687   0  18.83   9.540       2       6       4  0.085   1   0    0    0   \n",
       "688   0  27.42  14.500       2      14       8  3.085   1   1    1    0   \n",
       "689   1  41.00   0.040       2      10       4  0.040   0   1    1    0   \n",
       "\n",
       "     C12_enc  N13   N14  Target  \n",
       "0          2  100  1213       0  \n",
       "1          2  160     1       0  \n",
       "2          2  280     1       0  \n",
       "3          2    0     1       1  \n",
       "4          2   60   159       1  \n",
       "..       ...  ...   ...     ...  \n",
       "685        2    0     1       1  \n",
       "686        2    0    45       0  \n",
       "687        2  100     1       1  \n",
       "688        2  120    12       1  \n",
       "689        1  560     1       1  \n",
       "\n",
       "[690 rows x 15 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt(r'C:\\Users\\rsagu\\Downloads\\australian.dat',\n",
    "                     names='C1, N2, N3, C4_enc, C5_enc, C6_enc, N7, C8, C9, N10, C11, C12_enc, N13, N14, Target',\n",
    "                     dtype=None,\n",
    "                     delimiter=' ')\n",
    "dat_df = pd.DataFrame(data) \n",
    "dat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9757d163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>C4_enc</th>\n",
       "      <th>C5_enc</th>\n",
       "      <th>C6_enc</th>\n",
       "      <th>N7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>N10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12_enc</th>\n",
       "      <th>N13</th>\n",
       "      <th>N14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.678261</td>\n",
       "      <td>31.568203</td>\n",
       "      <td>4.758725</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>7.372464</td>\n",
       "      <td>4.692754</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>0.523188</td>\n",
       "      <td>0.427536</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>0.457971</td>\n",
       "      <td>1.928986</td>\n",
       "      <td>184.014493</td>\n",
       "      <td>1018.385507</td>\n",
       "      <td>0.444928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.467482</td>\n",
       "      <td>11.853273</td>\n",
       "      <td>4.978163</td>\n",
       "      <td>0.430063</td>\n",
       "      <td>3.683265</td>\n",
       "      <td>1.992316</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>0.499824</td>\n",
       "      <td>0.495080</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>0.498592</td>\n",
       "      <td>0.298813</td>\n",
       "      <td>172.159274</td>\n",
       "      <td>5210.102598</td>\n",
       "      <td>0.497318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.625000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.707500</td>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>396.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               C1          N2          N3      C4_enc      C5_enc      C6_enc  \\\n",
       "count  690.000000  690.000000  690.000000  690.000000  690.000000  690.000000   \n",
       "mean     0.678261   31.568203    4.758725    1.766667    7.372464    4.692754   \n",
       "std      0.467482   11.853273    4.978163    0.430063    3.683265    1.992316   \n",
       "min      0.000000   13.750000    0.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000   22.670000    1.000000    2.000000    4.000000    4.000000   \n",
       "50%      1.000000   28.625000    2.750000    2.000000    8.000000    4.000000   \n",
       "75%      1.000000   37.707500    7.207500    2.000000   10.000000    5.000000   \n",
       "max      1.000000   80.250000   28.000000    3.000000   14.000000    9.000000   \n",
       "\n",
       "               N7          C8          C9        N10         C11     C12_enc  \\\n",
       "count  690.000000  690.000000  690.000000  690.00000  690.000000  690.000000   \n",
       "mean     2.223406    0.523188    0.427536    2.40000    0.457971    1.928986   \n",
       "std      3.346513    0.499824    0.495080    4.86294    0.498592    0.298813   \n",
       "min      0.000000    0.000000    0.000000    0.00000    0.000000    1.000000   \n",
       "25%      0.165000    0.000000    0.000000    0.00000    0.000000    2.000000   \n",
       "50%      1.000000    1.000000    0.000000    0.00000    0.000000    2.000000   \n",
       "75%      2.625000    1.000000    1.000000    3.00000    1.000000    2.000000   \n",
       "max     28.500000    1.000000    1.000000   67.00000    1.000000    3.000000   \n",
       "\n",
       "               N13            N14      Target  \n",
       "count   690.000000     690.000000  690.000000  \n",
       "mean    184.014493    1018.385507    0.444928  \n",
       "std     172.159274    5210.102598    0.497318  \n",
       "min       0.000000       1.000000    0.000000  \n",
       "25%      80.000000       1.000000    0.000000  \n",
       "50%     160.000000       6.000000    0.000000  \n",
       "75%     272.000000     396.500000    1.000000  \n",
       "max    2000.000000  100001.000000    1.000000  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for statistics of the dataset\n",
    "dat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "391353ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   C1       690 non-null    int32  \n",
      " 1   N2       690 non-null    float64\n",
      " 2   N3       690 non-null    float64\n",
      " 3   C4_enc   690 non-null    int32  \n",
      " 4   C5_enc   690 non-null    int32  \n",
      " 5   C6_enc   690 non-null    int32  \n",
      " 6   N7       690 non-null    float64\n",
      " 7   C8       690 non-null    int32  \n",
      " 8   C9       690 non-null    int32  \n",
      " 9   N10      690 non-null    int32  \n",
      " 10  C11      690 non-null    int32  \n",
      " 11  C12_enc  690 non-null    int32  \n",
      " 12  N13      690 non-null    int32  \n",
      " 13  N14      690 non-null    int32  \n",
      " 14  Target   690 non-null    int32  \n",
      "dtypes: float64(3), int32(12)\n",
      "memory usage: 48.6 KB\n"
     ]
    }
   ],
   "source": [
    "dat_df.isna().sum()\n",
    "dat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0d0ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitthe data into features and Target Variables\n",
    "X = dat_df.iloc[:, :-1].values\n",
    "y = dat_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e0832",
   "metadata": {},
   "source": [
    "### Data Preprocessing: One Hot Encoding & Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e8ecc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding the columns: 3, 4, 5, 11\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "        transformers = [('one_hot_encoder', OneHotEncoder(categories = 'auto'),[3, 4, 5, 11])],\n",
    "        remainder = 'passthrough')\n",
    "\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "# Scaling - Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1cb9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train & test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64860591",
   "metadata": {},
   "source": [
    "3.\tCreate a decision tree model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the dataset is a binary classification problem we can build the Binary classification model to predict if the credit\n",
    "# was approved or rejected to customers.\n",
    "# First we see the model performance using DecisionTreeClassifier using different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "023dda2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 4, 'min_samples_leaf': 7, 'splitter': 'best'}\n",
      "Best score is 0.8622768222768222\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn import tree\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [4, None],\n",
    "              \"max_features\": randint(1, 10),\n",
    "              \"min_samples_leaf\": randint(1, 10),\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "             \"splitter\": [\"best\", \"random\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = tree.DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31da9d",
   "metadata": {},
   "source": [
    " After tuning the model we got the best score to be 86% which turns to be the good model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4dc7052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tree\n",
    "from sklearn import tree\n",
    "best_model = tree.DecisionTreeClassifier(criterion ='entropy', max_depth =5, max_features=7,\n",
    "                                        min_samples_leaf=5, splitter='best', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f12458b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82        82\n",
      "           1       0.70      0.93      0.80        56\n",
      "\n",
      "    accuracy                           0.81       138\n",
      "   macro avg       0.82      0.83      0.81       138\n",
      "weighted avg       0.84      0.81      0.81       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the model performance\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d472ad",
   "metadata": {},
   "source": [
    "Looking at the precision and recall values we can tell that the model performance is Excellent. \n",
    "Also, the time performance for the given set of data is fast.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d745a75",
   "metadata": {},
   "source": [
    "### 4.\tCreate a random forest model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f763b9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.904 (0.025)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate random forest algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
    "\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e3785db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855072463768116"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=170, random_state = 0)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06c94ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87        82\n",
      "           1       0.79      0.88      0.83        56\n",
      "\n",
      "    accuracy                           0.86       138\n",
      "   macro avg       0.85      0.86      0.85       138\n",
      "weighted avg       0.86      0.86      0.86       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b6a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d4479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d945819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57796fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 0.355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(max_depth=4, \n",
    "            n_estimators=200,\n",
    "            random_state=2)\n",
    "\n",
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = mse_test**(1/2)\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4299736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a good dataset for a first XGBoost model because all of the input variables are numeric and the problem is a \n",
    "# simple binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36b57c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:44:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsagu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print(xgb)\n",
    "\n",
    "# y_pred = xgb.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5873442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = xgb.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c976c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8484320557491289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c1e0b2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj80lEQVR4nO3deXRc9X338fdXmyXL8oItg7G8glnMaluAE7JASIgDCQ4BG2jTlpaWJwmkC2nOQ5/k0JR0eVLa9DQtbeM0HNKUBEsQeBwwuFmgpAkOHnnDNjg4BnvGC5YXvGv/Pn/cKzOWpdHI0p3RzP28ztHRvXd+M/O9Mtzvvb/fvd+fuTsiIhJfJfkOQERE8kuJQEQk5pQIRERiTolARCTmlAhERGKuLN8BDNSECRN8+vTp+Q5DRKSgNDU17XX32t5eK7hEMH36dBKJRL7DEBEpKGa2ra/X1DUkIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc5ElAjN7xMz2mNmGPl43M/uGmW0xs/VmNjeqWEREpG9RXhE8CizI8PrHgFnhz93Av0YYi4hIQWvadoCHX9hC07YDQ/7ZkT1H4O4vmdn0DE0WAv/hQR3slWY21swmufuuqGISERmu2ju7ONzSwaHj7cHvlnYOt7Rz6HgHm3Yd5D9XbqfLnYqyEh77/fnMmzZuyL47nw+UTQaSaeupcNspicDM7ia4amDq1Kk5CU5EJFvuzpHWDg63dJxyED/c0s6hcFv6evB6+4n3HG/vzOq72ju6WLl1X9Ekgqy5+xJgCUB9fb1m0hGRIdXa0dnL2XhH2oE688H8SGsHXf0cmSrKShhdWc7oyjJqqoLfZ4+poqayjJrKMkZXlge/q8qp6W5XWc7oqjK2Nh/l7u8maO/ooryshPkzxw/p/uczEewApqSt14XbRESy1tXlHG4NDsp9HsxbT97+7kE8+N3a0ZXxO8ygZkT3gTk4YE8eW8XoypoT6ycfyMtOOpjXVJZRWV562vtYN24kj/3+fFZu3cf8meOH9GoA8psIlgH3mtnjwFXAQY0PiMSLu9Pa0dXrmXamM/T09SNtHfQ3425lecmJA3VNZTljqsqpG1d14gy9r4N593p1RRklJZabP0of5k0bN+QJoFtkicDMvg9cA0wwsxTw50A5gLv/G7AcuAHYAhwDfjeqWEQkGp1dzpETZ9m9dZt0r7f36D9/96De1pn5bLzEOOXAPPWMkSe6TbrPvPs6iNdUllNRpkemMonyrqE7+nndgXui+n4RyczdOd7+bt/4oZbMB/HezsaPtvU/wDmyovSkA/MZ1RVMG199Uh94poP5yIpSzPJ7Nl7sCmKwWERO1dF9u2HagflQnwOdvXexdPQzwllWYqecYc+YUB0un3wQ714PuluCtqMqyygv1dn4cKdEIJIH7s7Rts5e+8IP9dk3fvK2Y1mcjY8acfIdKRNrKjmnNvPA5pgTB/dyKstLdDYeA0oEIqehraMrczdKHw8GHW4Nfh9p7aCzn7PxitKSU7pJzhxd2WdfePr66MpyRlWWUZrnAU4pDEoEEjtdXc7Rto6s+sIPdQ9whmfk3e9pae//dsNRI9IO0pXlnD22kprKmox3p6SvD+Z2Q5GBUCKQgtPSPcCZqS88Q1fLkdb+bzccUVZySh/45LFVp/SJ93oQrypn1DC43VAkW0oEklOdXcGj+H31gZ90lt7a+0G9rZ+Hf0qMEwfp7oN23biRaQOZPe9W6W777sF8RJnOxiU+lAiEpm0Hsnpi0d1pae86ceZ9crdJ7/VV0tcPt3RwuLWj33iqyktPOiiPHVnBlLT7xjMdzEdXlVOt2w1FBkSJIOaath3gjiUrae/sorTEWHDxWYysKD1pYDP9oN7emblPpbTETu4uqSxn2viRvfaFnziY9+ha0e2GIrmlRBBzL7y+58STnR1dzoqNuxlfPeLEmfb4URXMmFDd58Dmuw8BBdv08I9I4VEiiLnjbUFXTYkRSZ1zERn+lAhi7uWt+5k5oZpb5tVFUtVQRIY/JYIY27DjIJt2HeKrCy/it94zPd/hiEieaFQuxhoSSUaUlXDT5ZPzHYqI5JESQUy1tHfy9JodLLj4LMZUlec7HBHJIyWCmFqxcTeHWjpYXD+l/8YiUtSUCGKqMZGiblwV7xniuU9FpPAoEcRQcv8x/mfLXhbNm6J6OCKiRBBHTzSlMINb6+vyHYqIDANKBDHT1eU80ZTifedOYPLYqnyHIyLDgBJBzPz813vZ8c5xDRKLyAlKBDHTkEgxpqqcj8w+M9+hiMgwoUQQI+8ca2PFxt3cPGeyZr8SkROUCGLk/63dSVtHF4s0SCwiaZQIYqQhkeSis0dz0dlj8h2KiAwjSgQxsWHHQTbuPMRtV2iQWEROpkQQE42JJBVlJSy8TAXmRORkSgQx0NLeydNrd7LgorMYM1IF5kTkZEoEMfCjTW9z8Hi7nh0QkV4pEcRAQyLJ5LFVvPccFZgTkVMpERS51IGwwFx9nQrMiUivlAiK3BNNKQBunadnB0Skd5EmAjNbYGabzWyLmd3fy+tTzewFM1tjZuvN7IYo44mbri6nMZHi6nMmUDduZL7DEZFhKrJEYGalwMPAx4DZwB1mNrtHsy8DDe4+B7gd+Jeo4omjl7fuCwrM6dkBEckgyiuCK4Et7r7V3duAx4GFPdo4MDpcHgPsjDCe2Fm6KsnoyjKuV4E5EckgykQwGUimrafCbem+AnzazFLAcuDzvX2Qmd1tZgkzSzQ3N0cRa9E5eKyd5zfu5pMqMCci/cj3YPEdwKPuXgfcAHzXzE6Jyd2XuHu9u9fX1tbmPMhCtGzdDto6uvTsgIj0K8pEsANIPwrVhdvS3QU0ALj7y0AlMCHCmGJjaSLJ7EmjuXiyCsyJSGZRJoJVwCwzm2FmFQSDwct6tNkOXAdgZhcSJAL1/QzSxp0H2bBDBeZEJDuRJQJ37wDuBVYArxHcHbTRzB40s5vCZl8A/sDM1gHfB+50d48qprhoTKSoKC1h4eVn5zsUESkAZVF+uLsvJxgETt/2QNryJuDqKGOIm9aOTp5eu4PrLzqTsSMr8h2OiBSAfA8WyxD70aa3eedYu7qFRCRrSgRFpiGRCgvMacxdRLKjRFBEdrxznJ+90cwt8+ooVYE5EcmSEkERebIphTssUoE5ERkAJYIi0dXlNCSSXH3ueKacoQJzIpI9JYIisXLrPlIHjutJYhEZMCWCItGQCArMffSis/IdiogUGCWCInDweDvPbdjNwstVYE5EBk6JoAgsW7eTVhWYE5HTpERQBBoTSS6cNJqLJ4/uv7GISA9ZJwIz060ow9Bruw6xPnWQxfV1mOnZAREZuH4TgZm918w2Aa+H65eZmaaUHCYaEkkqSkv45OU95/wREclONlcE/wB8FNgH4O7rgA9EGZRkp7Wjk6fX7OAjF53JuGoVmBOR05NV15C7J3ts6owgFhmgH2/aw4Fj7RokFpFByaYMddLM3gu4mZUDf0Qwv4DkWUMiydljKnnfuSowJyKnL5srgs8A9xBMPL8DuBz4XIQxSRZ2vnOcl95o5lYVmBORQcrmiuB8d//N9A1mdjXw82hCkmx0F5i7dZ66hURkcLK5IvinLLdJjnR1OY1NKd57znimjtddvSIyOH1eEZjZe4D3ArVmdl/aS6MB1THIo5Vv7mP7/mPc95Hz8h2KiBSBTF1DFcCosE1N2vZDwK1RBiWZNSZS1FSWseBiFZgTkcHrMxG4+38D/21mj7r7thzGJBkcamln+au7WFRfpwJzIjIkshksPmZmDwEXAZXdG939Q5FFJX1atlYF5kRkaGUzWPwYQXmJGcBfAG8BqyKMSTJoTCS54KwaLpk8Jt+hiEiRyCYRjHf3bwPt7v7f7v57gK4G8uD13YdYlzrI4vopKjAnIkMmm66h9vD3LjO7EdgJnBFdSNKXhlUpykuNT85RgTkRGTrZJIK/NLMxwBcInh8YDfxxlEHJqdo6unhqTYrrZ5/FGSowJyJDqN9E4O7PhIsHgWvhxJPFkkM/ee1tDhxrZ1F9Xb5DEZEik+mBslJgMUGNoefdfYOZfRz4P0AVMCc3IQrA0kSSSWMqef+s2nyHIiJFJtMVwbeBKcArwDfMbCdQD9zv7k/nIDYJ7Tp4nJd+1cw9156rAnMiMuQyJYJ64FJ37zKzSmA3cI6778tNaNLtyaYUXQ63zlO3kIgMvUy3j7a5exeAu7cAWweaBMxsgZltNrMtZnZ/H20Wm9kmM9toZt8byOfHQVeX05BIMX/mGUwbX53vcESkCGW6IrjAzNaHywacE64b4O5+aaYPDscYHgY+AqSAVWa2zN03pbWZBfwZcLW7HzCziYPYl6L0ylv72b7/GH/ykVn5DkVEilSmRHDhID/7SmCLu28FMLPHgYXAprQ2fwA87O4HANx9zyC/s+g0rEpSM6KMBRdNyncoIlKkMhWdG2yhuclA+lzHKeCqHm3OAzCznxOUtv6Kuz/f84PM7G7gboCpU6cOMqzCcailneUbdvGpuXVUVajAnIhEI6vJ6yNUBswCrgHuAL5lZmN7NnL3Je5e7+71tbXxuX3ymXW7aGnv4jYVmBORCEWZCHYQ3H7arS7cli4FLHP3dnd/E/gVQWIQgmcHzj+zhkvrVGBORKKTVSIwsyozO3+An70KmGVmM8ysArgdWNajzdMEVwOY2QSCrqKtA/yeorR592HWJd9h8RUqMCci0eo3EZjZJ4C1wPPh+uVm1vOAfgp37wDuBVYArwEN7r7RzB40s5vCZiuAfWa2CXgB+KKeUwg0JpJBgbnLz853KCJS5LIpOvcVgjuAXgRw97VmNiObD3f35cDyHtseSFt24L7wR0JtHV38YM0OPnzhmYwfNSLf4YhIkcuma6jd3Q/22OZRBCOBn77+NvuPtrH4Cg0Si0j0srki2GhmvwGUhg+A/SHwi2jDireGRIqzRlfyARWYE5EcyOaK4PME8xW3At8jKEf9xxHGFGu7D7bw4uY93DJvsgrMiUhOZHNFcIG7fwn4UtTBCDy5Oigwt2ieuoVEJDeyuSL4ezN7zcy+amYXRx5RjLk7jYkkV804g+kTVGBORHKj30Tg7tcSzEzWDHzTzF41sy9HHlkMvfLmft7ad4zFepJYRHIoqwfK3H23u38D+AzBMwUPZH6HnI6GRIpRI8q44RIVmBOR3MnmgbILzewrZvYqweT1vyAoFyFD6HBLO8tf3cUnLjtbBeZEJKeyGSx+BFgKfNTdd0YcT2w9s34Xx9s7WazJ6UUkx/pNBO7+nlwEEncNiSTnnTmKy6eMzXcoIhIzfSYCM2tw98Vhl1D6k8RZzVAm2Xvj7cOs2f4OX77xQhWYE5Gcy3RF8Efh74/nIpA4a0gkKSsxbp4zOd+hiEgM9TlY7O67wsXPufu29B/gc7kJr/i1d3bxg9UqMCci+ZPN7aMf6WXbx4Y6kLj6yWt72He0jcVXaJBYRPIj0xjBZwnO/Gea2fq0l2qAn0cdWFw0JpKcOXqECsyJSN5kGiP4HvAc8DfA/WnbD7v7/kijiom3D7XwwuY9fOaD51BWmu/po0UkrjIlAnf3t8zsnp4vmNkZSgaDd6LAnEpKiEge9XdF8HGgieD20fT7Gh2YGWFcRS8oMJfiyhlnMEMF5kQkj/pMBO7+8fB3VtNSysCseusAb+49yj3XnpvvUEQk5rKpNXS1mVWHy582s6+b2dToQytuDYlkWGDurHyHIiIxl80I5b8Cx8zsMuALwK+B70YaVZE70trBs+t38YnLJjGyIptyTyIi0ckmEXS4uwMLgX9294cJbiGV0/TMup0cb+/UILGIDAvZnI4eNrM/A34LeL+ZlQDl0YZV3BoSSWZNHMUcFZgTkWEgmyuC2wgmrv89d99NMBfBQ5FGVcS27DnM6u3vsLh+igrMiciwkM1UlbuBx4AxZvZxoMXd/yPyyIpUQyIVFJibqwJzIjI8ZHPX0GLgFWARsBj4pZndGnVgxSgoMJfiugsnMkEF5kRkmMhmjOBLwBXuvgfAzGqBHwNPRBlYMXrh9T3sPdKmyelFZFjJZoygpDsJhPZl+T7poSGRZGLNCD54ngrMicjwkc0VwfNmtgL4frh+G7A8upCK055DLbywuZm7PzBTBeZEZFjJZs7iL5rZp4D3hZuWuPtT0YZVfJ5cvYPOLmfRPM07ICLDS6b5CGYBfwecA7wK/Km778hVYMUkKDCX5Irp45hZOyrf4YiInCRTH8UjwDPALQQVSP9poB9uZgvMbLOZbTGz+zO0u8XM3MzqB/odhaBp2wG27j2qQWIRGZYydQ3VuPu3wuXNZrZ6IB9sZqXAwwRTXaaAVWa2zN039WhXA/wR8MuBfH4hWboqSXVFKTdcMinfoYiInCJTIqg0szm8Ow9BVfq6u/eXGK4Etrj7VgAze5ygXtGmHu2+CnwN+OIAYy8IR1o7ePbVXXzi0rOpHqECcyIy/GQ6Mu0Cvp62vjtt3YEP9fPZk4Fk2noKuCq9gZnNBaa4+7Nm1mciMLO7gbsBpk4trArYy9fv4lhbJ4uvULeQiAxPmSamuTbKLw6L130duLO/tu6+BFgCUF9f71HGNdSWJpKcU1vN3Klj8x2KiEivoryhfQeQfhpcF27rVgNcDLxoZm8B84FlxTRgvGXPEZq2HeC2K1RgTkSGrygTwSpglpnNMLMK4HZgWfeL7n7Q3Se4+3R3nw6sBG5y90SEMeVUY1OS0hLj5jl6dkBEhq/IEoG7dwD3AiuA14AGd99oZg+a2U1Rfe9w0d7ZxZNNO/jQBROprVGBOREZvvq9jcWCPo3fBGa6+4PhfMVnufsr/b3X3ZfToxyFuz/QR9trsoq4QLy4uZm9R1q5Tc8OiMgwl80Vwb8A7wHuCNcPEzwfIBk0JJLU1ozgmvNVYE5EhrdsEsFV7n4P0ALg7geAikijKnB7Drfw09f38Km5k1VgTkSGvWyOUu3hU8IOJ+Yj6Io0qgL3VFhgTiUlRKQQZJMIvgE8BUw0s78C/gf460ijKmDuztJEkvpp4zhHBeZEpABkU4b6MTNrAq4jKC/xSXd/LfLICtTq7QfY2nyUz9xyTr5DERHJSjZ3DU0FjgE/TN/m7tujDKxQNaxKMbKilBsvVYE5ESkM2VRBe5ZgfMCASmAGsBm4KMK4CtLR1g6eWb+Tj186SQXmRKRgZNM1dEn6elgo7nORRVTAnn11F0fbOrlNBeZEpIAM+N7GsPz0Vf02jKHGRJKZtdXMnTou36GIiGQtmzGC+9JWS4C5wM7IIipQv24+wqq3DnD/xy5QgTkRKSjZdGTXpC13EIwZPBlNOIWrMZGitMT41NzJ+Q5FRGRAMiaC8EGyGnf/0xzFU5A6Ort4cnWKa8+fyMSaynyHIyIyIH2OEZhZmbt3AlfnMJ6C9OLmZpoPt7K4XuWmRaTwZLoieIVgPGCtmS0DGoGj3S+6+w8ijq1gNCSSTBg1gmsvmJjvUEREBiybMYJKYB/BHMXdzxM4oEQANB9u5aev7+Gu982gXAXmRKQAZUoEE8M7hjbwbgLoVlDzBkfpqTUpOrqcRSowJyIFKlMiKAVGcXIC6KZEQFBgriGRYt60cZw7UQXmRKQwZUoEu9z9wZxFUoBWb3+HLXuO8LVbLum/sYjIMJWpU1tPRfWjMZEMC8ydne9QREROW6ZEcF3OoihAx9o6+OG6ndx4ySRGqcCciBSwPhOBu+/PZSCF5tn1QYG5xSowJyIFTvc7nqbGRIqZE6qpn6YCcyJS2JQITsPW5iO88tZ+FtVPUYE5ESl4SgSnobEpKDB3iwrMiUgRUCIYoI7OLp5sSnHt+bVMHK0CcyJS+JQIBuilN5rZc7hVTxKLSNFQIhigpauSTBhVwYdUYE5EioQSwQDsPdLKT17bw6fm1qnAnIgUDR3NBuCp1TuCAnPzNO+AiBQPJYIsBQXmksyZOpZZZ9b0/wYRkQIRaSIwswVmttnMtpjZ/b28fp+ZbTKz9Wb2EzObFmU8g7E2+Q5v7DnCbRokFpEiE1kiCOc7fhj4GDAbuMPMZvdotgaod/dLgSeAv40qnsFqSCSpKi/lxksn5TsUEZEhFeUVwZXAFnff6u5twOPAwvQG7v6Cux8LV1cCw7LzPSgwt4sbL51ETWV5vsMRERlSUSaCyUAybT0VbuvLXcBzvb1gZnebWcLMEs3NzUMYYnaee3U3R1o7WKxuIREpQsNisNjMPg3UAw/19rq7L3H3enevr62tzW1wwNJEkhkTqrliugrMiUjxiTIR7ADST6Hrwm0nMbMPA18CbnL31gjjOS1v7j3KK2/uZ1F9nQrMiUhRijIRrAJmmdkMM6sAbgeWpTcwsznANwmSwJ4IYzltTzQlKTG4Ze6wHL4QERm0yBKBu3cA9wIrgNeABnffaGYPmtlNYbOHgFFAo5mtNbNlfXxcXnR0dvFEU4przp/ImSowJyJFKtI5Ft19ObC8x7YH0pY/HOX3D9bP3tjL24da+YubNEgsIsVrWAwWD1cNiSTjq1VgTkSKmxJBH/YdaeXHr73NzXMmU1GmP5OIFC8d4frw1JodtHe6JqcXkaKnRNCL7gJzl08Zy3kqMCciRU6JoBfrUgf51dtH9CSxiMSCEkEvGhJJKstL+MRlKjAnIsVPiaCH422d/HDtTm64RAXmRCQelAh6eG7DLg63dmjeARGJDSWCHhoSSaaPH8mVM87IdygiIjmhRJBm276jrNy6n0X1U1RgTkRiQ4kgTWMipQJzIhI7SgShzi7niaYUHzyvlrPGqMCciMSHEkHopTea2X2oRc8OiEjsKBGEGhNJzqiu4LoLz8x3KCIiOaVEAOw/2saPNqnAnIjEk456pBWYU7eQiMRQ7BOBu9OYSHLZlLGcf5YKzIlI/MQ+EaxPHeT13YdZXK9bRkUknmKfCN4tMHd2vkMREcmLWCeC422dLFu7kxsunsRoFZgTkZiKdSJ4fmNQYG6RBolFJMZinQgaVqWYNn4k82eqwJyIxFdsE8H2fcd4ees+Fs2rU4E5EYm12CaCxqZkUGBunu4WEpF4i2Ui6C4w94Hzapk0pirf4YiI5FUsE8H/bNnLroMqMCciAjFNBA2rkowbWc51F07MdygiInkXu0Sw/2gb/7VpNzfPqWNEWWm+wxERybvYJYKnuwvMXaFBYhERiFkicHcaEkkurRvDBWeNznc4IiLDQqwSwYYdh8ICcxokFhHpFmkiMLMFZrbZzLaY2f29vD7CzJaGr//SzKZHGc/SxHZGlKnAnIhIusgSgZmVAg8DHwNmA3eY2eweze4CDrj7ucA/AF+LKp6Xf72XhkSKq2aewZgqFZgTEekW5RXBlcAWd9/q7m3A48DCHm0WAt8Jl58ArrMI6j00bTvAbz/yCm0dXaz89X6ath0Y6q8QESlYUSaCyUAybT0Vbuu1jbt3AAeB8T0/yMzuNrOEmSWam5sHHMjKrfvo6HQAOru6WLl134A/Q0SkWBXEYLG7L3H3enevr62tHfD7588cz4jyEkoNystKmD/zlFwjIhJbZRF+9g4g/facunBbb21SZlYGjAGG/HR93rRxPPb781m5dR/zZ45n3rRxQ/0VIiIFK8pEsAqYZWYzCA74twO/0aPNMuB3gJeBW4GfurtHEcy8aeOUAEREehFZInD3DjO7F1gBlAKPuPtGM3sQSLj7MuDbwHfNbAuwnyBZiIhIDkV5RYC7LweW99j2QNpyC7AoyhhERCSzghgsFhGR6CgRiIjEnBKBiEjMKRGIiMScRXS3ZmTMrBnYdppvnwDsHcJwCoH2OR60z/EwmH2e5u69PpFbcIlgMMws4e71+Y4jl7TP8aB9joeo9lldQyIiMadEICISc3FLBEvyHUAeaJ/jQfscD5Hsc6zGCERE5FRxuyIQEZEelAhERGKuKBOBmS0ws81mtsXM7u/l9RFmtjR8/ZdmNj0PYQ6pLPb5PjPbZGbrzewnZjYtH3EOpf72Oa3dLWbmZlbwtxpms89mtjj8t95oZt/LdYxDLYv/tqea2Qtmtib87/uGfMQ5VMzsETPbY2Yb+njdzOwb4d9jvZnNHfSXuntR/RCUvP41MBOoANYBs3u0+Rzwb+Hy7cDSfMedg32+FhgZLn82DvsctqsBXgJWAvX5jjsH/86zgDXAuHB9Yr7jzsE+LwE+Gy7PBt7Kd9yD3OcPAHOBDX28fgPwHGDAfOCXg/3OYrwiuBLY4u5b3b0NeBxY2KPNQuA74fITwHVmZjmMcaj1u8/u/oK7HwtXVxLMGFfIsvl3Bvgq8DWgJZfBRSSbff4D4GF3PwDg7ntyHONQy2afHRgdLo8BduYwviHn7i8RzM/Sl4XAf3hgJTDWzCYN5juLMRFMBpJp66lwW69t3L0DOAgU8kTG2exzursIzigKWb/7HF4yT3H3Z3MZWISy+Xc+DzjPzH5uZivNbEHOootGNvv8FeDTZpYimP/k87kJLW8G+v97vyKdmEaGHzP7NFAPfDDfsUTJzEqArwN35jmUXCsj6B66huCq7yUzu8Td38lnUBG7A3jU3f/ezN5DMOvhxe7ele/ACkUxXhHsAKakrdeF23ptY2ZlBJeT+3ISXTSy2WfM7MPAl4Cb3L01R7FFpb99rgEuBl40s7cI+lKXFfiAcTb/zilgmbu3u/ubwK8IEkOhymaf7wIaANz9ZaCSoDhbscrq//eBKMZEsAqYZWYzzKyCYDB4WY82y4DfCZdvBX7q4ShMgep3n81sDvBNgiRQ6P3G0M8+u/tBd5/g7tPdfTrBuMhN7p7IT7hDIpv/tp8muBrAzCYQdBVtzWGMQy2bfd4OXAdgZhcSJILmnEaZW8uA3w7vHpoPHHT3XYP5wKLrGnL3DjO7F1hBcMfBI+6+0cweBBLuvgz4NsHl4xaCQZnb8xfx4GW5zw8Bo4DGcFx8u7vflLegBynLfS4qWe7zCuB6M9sEdAJfdPeCvdrNcp+/AHzLzP6EYOD4zkI+sTOz7xMk8wnhuMefA+UA7v5vBOMgNwBbgGPA7w76Owv47yUiIkOgGLuGRERkAJQIRERiTolARCTmlAhERGJOiUBEJOaUCGRYMrNOM1ub9jM9Q9sjQ/B9j5rZm+F3rQ6fUB3oZ/y7mc0Ol/9Pj9d+MdgYw8/p/rtsMLMfmtnYftpfXujVOCV6un1UhiUzO+Luo4a6bYbPeBR4xt2fMLPrgb9z90sH8XmDjqm/zzWz7wC/cve/ytD+ToKqq/cOdSxSPHRFIAXBzEaF8yisNrNXzeyUSqNmNsnMXko7Y35/uP16M3s5fG+jmfV3gH4JODd8733hZ20wsz8Ot1Wb2bNmti7cflu4/UUzqzez/wtUhXE8Fr52JPz9uJndmBbzo2Z2q5mVmtlDZrYqrDH/v7L4s7xMWGzMzK4M93GNmf3CzM4Pn8R9ELgtjOW2MPZHzOyVsG1vFVslbvJde1s/+unth+Cp2LXhz1MET8GPDl+bQPBUZfcV7ZHw9xeAL4XLpQT1hiYQHNirw+3/G3igl+97FLg1XF4E/BKYB7wKVBM8lb0RmAPcAnwr7b1jwt8vEs550B1TWpvuGG8GvhMuVxBUkawC7ga+HG4fASSAGb3EeSRt/xqBBeH6aKAsXP4w8GS4fCfwz2nv/2vg0+HyWIJaRNX5/vfWT35/iq7EhBSN4+5+efeKmZUDf21mHwC6CM6EzwR2p71nFfBI2PZpd19rZh8kmKzk52FpjQqCM+nePGRmXyaoU3MXQf2ap9z9aBjDD4D3A88Df29mXyPoTvrZAPbrOeAfzWwEsAB4yd2Ph91Rl5rZrWG7MQTF4t7s8f4qM1sb7v9rwI/S2n/HzGYRlFko7+P7rwduMrM/DdcrganhZ0lMKRFIofhNoBaY5+7tFlQUrUxv4O4vhYniRuBRM/s6cAD4kbvfkcV3fNHdn+heMbPremvk7r+yYK6DG4C/NLOfuPuD2eyEu7eY2YvAR4HbCCZagWC2qc+7+4p+PuK4u19uZiMJ6u/cA3yDYAKeF9z95nBg/cU+3m/ALe6+OZt4JR40RiCFYgywJ0wC1wKnzLlswTzMb7v7t4B/J5jubyVwtZl19/lXm9l5WX7nz4BPmtlIM6sm6Nb5mZmdDRxz9/8kKObX25yx7eGVSW+WEhQK6766gOCg/tnu95jZeeF39sqD2eb+EPiCvVtKvbsU8Z1pTQ8TdJF1WwF83sLLIwuq0krMKRFIoXgMqDezV4HfBl7vpc01wDozW0Nwtv2P7t5McGD8vpmtJ+gWuiCbL3T31QRjB68QjBn8u7uvAS4BXgm7aP4c+Mte3r4EWN89WNzDfxFMDPRjD6ZfhCBxbQJWWzBp+Tfp54o9jGU9wcQsfwv8Tbjv6e97AZjdPVhMcOVQHsa2MVyXmNPtoyIiMacrAhGRmFMiEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmPv/hGLozKq5MCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, marker = '.')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3b76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee14ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
