{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbcad47f",
   "metadata": {},
   "source": [
    "# NLP(Natural Language Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052d065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Donec', 'vestibulum', 'vitae', 'enim', 'sed', 'hendrerit', '.', 'Class', 'aptent', 'taciti', 'sociosqu', 'ad', 'litora', 'torquent', 'per', 'conubia', 'nostra', ',', 'per', 'inceptos', 'himenaeos', '.', 'Donec', 'sodales', 'orci', 'non', 'sapien', 'malesuada', 'ultricies', '.', 'Sed', 'odio', 'lectus', ',', 'dapibus', 'ut', 'ornare', 'convallis', ',', 'dapibus', 'ac', 'nulla', '.', 'Nullam', 'dapibus', 'mi', 'quis', 'velit', 'imperdiet', ',', 'et', 'tempor', 'ligula', 'imperdiet', '.', 'Donec', 'ultricies', 'nisi', 'sit', 'amet', 'velit', 'dapibus', ',', 'quis', 'tincidunt', 'nisl', 'porta', '.', 'Cras', 'fringilla', 'arcu', 'quis', 'felis', 'egestas', 'ultricies', '.', 'Integer', 'et', 'ligula', 'a', 'risus', 'porta', 'euismod', 'id', 'non', 'sem', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# https://www.lipsum.com\n",
    "\n",
    "text = '''\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
    "Donec vestibulum vitae enim sed hendrerit. Class aptent taciti \n",
    "sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos.\n",
    "Donec sodales orci non sapien malesuada ultricies. Sed odio lectus, dapibus\n",
    "ut ornare convallis, dapibus ac nulla. Nullam dapibus mi quis velit imperdiet,\n",
    "et tempor ligula imperdiet. Donec ultricies nisi sit amet velit dapibus, quis \n",
    "tincidunt nisl porta. Cras fringilla arcu quis felis egestas ultricies. Integer\n",
    "et ligula a risus porta euismod id non sem.\n",
    "'''\n",
    "print(word_tokenize(text))\n",
    "\n",
    "#keras has a tokenizer\n",
    "#boundary of words can be complicated, but in english this is not as complex as in other languages\n",
    "#handling symbols can also be hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c01adb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd0e887f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Alice', \"'\", 's', 'Adventures', 'in', ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiw = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "aiw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa60881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f27cb4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rsagu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\rsagu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28edce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rsagu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8aa0ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Aliquam', 'rhoncus', 'risus', 'vulputate', 'condimentum', 'lobortis', '.', 'Pellentesque', 'at', 'semper', 'magna', '.', 'Nullam', 'nibh', 'dolor', ',', 'facilisis', 'at', 'massa', 'nec', ',', 'consequat', 'volutpat', 'elit', '.', 'Morbi', 'ut', 'massa', 'pulvinar', ',', 'mollis', 'mi', 'tincidunt', ',', 'feugiat', 'urna', '.', 'Curabitur', 'non', 'ultrices', 'tortor', '.', 'Proin', 'ac', 'venenatis', 'tellus', '.', 'Vestibulum', 'quis', 'rhoncus', 'mi', ',', 'sed', 'dictum', 'nisi', '.', 'Curabitur', 'tristique', 'nunc', 'nec', 'erat', 'venenatis', 'convallis', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#https://www.lipsum.com/feed/html\n",
    "\n",
    "text = '''\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
    "Aliquam rhoncus risus vulputate condimentum lobortis. \n",
    "Pellentesque at semper magna. Nullam nibh dolor, facilisis \n",
    "at massa nec, consequat volutpat elit. Morbi ut massa pulvinar, \n",
    "mollis mi tincidunt, feugiat urna. Curabitur non ultrices tortor. \n",
    "Proin ac venenatis tellus. Vestibulum quis rhoncus mi, sed dictum nisi. \n",
    "Curabitur tristique nunc nec erat venenatis convallis.\n",
    "'''\n",
    "\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e4ad1",
   "metadata": {},
   "source": [
    "# Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5eef1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\rsagu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9d5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
