{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a8f4a5",
   "metadata": {},
   "source": [
    "# Week-18 Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94210127",
   "metadata": {},
   "source": [
    "#### 1.\tWhat is a neural network? What are the general steps required to build a neural network? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7515a",
   "metadata": {},
   "source": [
    "#### Neural network\n",
    "A large connected network which is passing the inputs(values) through hidden layers and there is some computation happening\n",
    "to get the desired output. Purely considering the Neural Network has three layers: Input Layer, Hidden Layer, \n",
    "and Output Layer. While the inputs and outputs correspond to visible things \n",
    "and they can be stored as data, the values in the hidden layer aren't something we have \n",
    "data about, or anything we observe directly. Each node in the hidden layer is an aggregation of information that comes from input \n",
    "data, and each node adds to the model's ability to capture interactions.\n",
    "So the more nodes we have, the more interactions we can capture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c2c0f1",
   "metadata": {},
   "source": [
    "#### The general steps required to build a neural network:\n",
    "\n",
    "When the hidden layers recieve information from inputs\n",
    "\n",
    "The connections between the two layers assign weights to each input randomly\n",
    "\n",
    "Then bias will be added to every input after weights are multiplied with them individually\n",
    "\n",
    "The weighted sum is then transferred to the activation function(allows the model to capture non-linearities)\n",
    "\n",
    "combination = bias +weights * inputs\n",
    "\n",
    "An activation function is something applied to the value coming into a node, which then transforms \n",
    "it into the value stored in that node, or the node output\n",
    "\n",
    "Weights are adjusted, and the output is back-propagated to minimize error based on loss obtained in previous epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a94020",
   "metadata": {},
   "source": [
    "#### 2.\tGenerally, how do you check the performance of a neural network? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77bd36",
   "metadata": {},
   "source": [
    "Generally as a performance metric we use Mean-Squared-Error, Root-Mean-Squared-Error, Mean_Absolute_Error, \n",
    "R square for regression type of problems and when it comes to classification problems we use True Positive rate,\n",
    "False Positive rate, accuracy, precision nad recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3e8fc",
   "metadata": {},
   "source": [
    "Its hard to make accurate prediction with multiple points. So, we use a loss function to\n",
    "aggregate all the errors into a single measure of the model's predictive performance. A common loss \n",
    "function for regression tasks is mean-squared error. Here we square each error, \n",
    "and take the average of that as a measure of model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6cc12b",
   "metadata": {},
   "source": [
    "Lower values mean a better model, so our goal is to find the weights giving the lowest value for the loss function. \n",
    "We do this with an algorithm called gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97a468",
   "metadata": {},
   "source": [
    "#### 3.\tCreate a neural network using keras to predict the outcome of either of these datasets: \n",
    "\n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "\n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da918343",
   "metadata": {},
   "source": [
    "The common name for Abalone is sea snail. we can determine the age of the abalone by cutting the shell through the cone,\n",
    "stained and the rings are counted using the microscope. All these is a time consuming process that can be simplified \n",
    "using neural networks. Here, we can predict their age using physical measurements like length, height, weight and\n",
    "other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54164347",
   "metadata": {},
   "source": [
    "Lets import our Abalone dataset and some dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb31df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74082566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset (Abalone dataset)\n",
    "target_url = (r\"A:\\launch_code_STL\\Final_Homework\\week-17\\abalone.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9487baa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 9)\n",
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    }
   ],
   "source": [
    "abalone_df = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone_df.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "\n",
    "print(abalone_df.shape)\n",
    "print(abalone_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e49bf3",
   "metadata": {},
   "source": [
    "The dataset contains 4177 samples and each sample has 9 features('Sex', 'Length', 'Diameter', 'Height', 'Whole weight', \n",
    "'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings') The Rings feature is the target variable and as given \n",
    "in the documentation, adding 1.5 to the ring attribute gives the age of the abalone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32ea79",
   "metadata": {},
   "source": [
    "###  Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43037a",
   "metadata": {},
   "source": [
    "#### Encoding the input columns\n",
    "\n",
    "Out of the 8 input columns, 'Sex' column is a categorical attribute, we need to perform one hot encoding, we use \n",
    "get_dummies() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c500948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the sex attribute.\n",
    "df_dummies = pd.get_dummies(abalone_df['Sex'], prefix = \"Sex_\") # drop_first parameter is set to True, this means\n",
    "                                                                           # that if there are n categories in the column,\n",
    "                                                                           # n-1 columns are returned instead of n.\n",
    "\n",
    "# Inserting dummy columns\n",
    "for column in df_dummies.columns:\n",
    "    abalone_df[column] = df_dummies[column]  # one-hot encoded columns are appended to the data frame\n",
    "    \n",
    "# Dropping the original column\n",
    "abalone_df = abalone_df.drop(columns = ['Sex'])     # original 'Sex' attribute column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7e21724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight  Rings  Sex__F  Sex__I  Sex__M  \n",
      "0           0.1500     15       0       0       1  \n",
      "1           0.0700      7       0       0       1  \n",
      "2           0.2100      9       1       0       0  \n",
      "3           0.1550     10       0       0       1  \n",
      "4           0.0550      7       0       1       0  \n",
      "...            ...    ...     ...     ...     ...  \n",
      "4172        0.2490     11       1       0       0  \n",
      "4173        0.2605     10       0       0       1  \n",
      "4174        0.3080      9       0       0       1  \n",
      "4175        0.2960     10       1       0       0  \n",
      "4176        0.4950     12       0       0       1  \n",
      "\n",
      "[4177 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(abalone_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a5c7a",
   "metadata": {},
   "source": [
    "#### Encoding the output columns\n",
    "\n",
    "The attribute 'Rings' is with continuous values ranging from 1 to 29. we can split these into 3 categories — \n",
    "less than 10(young), between 10 and 20 (middle age), between 20 and 30(old).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa9ec6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rings_label(x):\n",
    "    if x<=10:\n",
    "        return 'young'\n",
    "    if x<=20:\n",
    "        return 'middle age'\n",
    "    if x<=30:\n",
    "        return 'old'\n",
    "    \n",
    "abalone_df['Rings'] = abalone_df['Rings'].apply(rings_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9aa1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight       Rings  Sex__F  Sex__I  Sex__M  \n",
      "0           0.1500  middle age       0       0       1  \n",
      "1           0.0700       young       0       0       1  \n",
      "2           0.2100       young       1       0       0  \n",
      "3           0.1550       young       0       0       1  \n",
      "4           0.0550       young       0       1       0  \n",
      "...            ...         ...     ...     ...     ...  \n",
      "4172        0.2490  middle age       1       0       0  \n",
      "4173        0.2605       young       0       0       1  \n",
      "4174        0.3080       young       0       0       1  \n",
      "4175        0.2960       young       1       0       0  \n",
      "4176        0.4950  middle age       0       0       1  \n",
      "\n",
      "[4177 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(abalone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6478143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the Rings attribute.\n",
    "df_dummies = pd.get_dummies(abalone_df['Rings'])\n",
    "\n",
    "# Inserting dummy columns\n",
    "for column in df_dummies.columns:\n",
    "    abalone_df[column] = df_dummies[column]\n",
    "    \n",
    "# Dropping the original column\n",
    "df = abalone_df.drop(columns = ['Rings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95b15b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the input and output columns to separate the dataset in the later cells.\n",
    "\n",
    "input_columns = df.columns.tolist()\n",
    "input_columns.remove('young')\n",
    "input_columns.remove('middle age')\n",
    "input_columns.remove('old')\n",
    "\n",
    "output_columns = ['young', 'middle age', 'old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f0bdf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight  Sex__F  Sex__I  Sex__M  middle age  old  young  \n",
      "0           0.1500       0       0       1           1    0      0  \n",
      "1           0.0700       0       0       1           0    0      1  \n",
      "2           0.2100       1       0       0           0    0      1  \n",
      "3           0.1550       0       0       1           0    0      1  \n",
      "4           0.0550       0       1       0           0    0      1  \n",
      "...            ...     ...     ...     ...         ...  ...    ...  \n",
      "4172        0.2490       1       0       0           1    0      0  \n",
      "4173        0.2605       0       0       1           0    0      1  \n",
      "4174        0.3080       0       0       1           0    0      1  \n",
      "4175        0.2960       1       0       0           0    0      1  \n",
      "4176        0.4950       0       0       1           1    0      0  \n",
      "\n",
      "[4177 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40278bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train, val and test set -- 80-10-10 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, an 80-20 split\n",
    "train_df, val_test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "# Then split the 20% into half\n",
    "val_df, test_df = train_test_split(val_test_df, test_size = 0.5)\n",
    "\n",
    "# Splitting into X (input) and y (output)\n",
    "\n",
    "X_train, y_train = np.array(train_df[input_columns]), np.array(train_df[output_columns])\n",
    "\n",
    "X_val, y_val = np.array(val_df[input_columns]), np.array(val_df[output_columns])\n",
    "\n",
    "X_test, y_test = np.array(test_df[input_columns]), np.array(test_df[output_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75f8c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "Xtrain = sc.fit_transform(X_train)\n",
    "Xval = sc.transform(X_val)\n",
    "Xtest = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0c2878a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3225 - mean_absolute_error: 0.3225 - val_loss: 0.2564 - val_mean_absolute_error: 0.2564\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2370 - mean_absolute_error: 0.2370 - val_loss: 0.2365 - val_mean_absolute_error: 0.2365\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2308 - mean_absolute_error: 0.2308 - val_loss: 0.2351 - val_mean_absolute_error: 0.2351\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2302 - mean_absolute_error: 0.2302 - val_loss: 0.2347 - val_mean_absolute_error: 0.2347\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2346 - val_mean_absolute_error: 0.2346\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2346 - val_mean_absolute_error: 0.2346\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2299 - mean_absolute_error: 0.2299 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import keras.callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(32, activation = 'relu', input_shape = X_train[0].shape),\n",
    "    layers.Dense(8, activation = 'relu'),\n",
    "    layers.Dense(3, activation = 'softmax')])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model.compile(optimizer = 'Adam', loss = 'mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "\n",
    "# model.compile(optimizer = 'Adam', loss = 'CategoricalCrossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 10, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2479e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 847us/step - loss: 0.2361 - mean_absolute_error: 0.2361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23607148230075836, 0.23607148230075836]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22e1a9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 32)                352       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary for number of parameters used in the algorithm\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818f2e5",
   "metadata": {},
   "source": [
    "#### 4.\tWrite another algorithm to predict the same result as the previous question using either KNN or logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bba8cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 9)\n",
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    }
   ],
   "source": [
    "abalone_df = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone_df.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "# abalone_df = pd.DataFrame(abalone_df, columns=abalone_df.columns)\n",
    "# y = abalone_df.Rings\n",
    "\n",
    "print(abalone_df.shape)\n",
    "print(abalone_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e53c5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dictionary = {'M': 1, 'F' : 2,'I':3}\n",
    "abalone_df['Sex'] = abalone_df['Sex'].apply(lambda x: sex_dictionary[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26205293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex                 int64\n",
       "Length            float64\n",
       "Diameter          float64\n",
       "Height            float64\n",
       "Whole weight      float64\n",
       "Shucked weight    float64\n",
       "Viscera weight    float64\n",
       "Shell weight      float64\n",
       "Rings               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f326ad3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole weight      0\n",
       "Shucked weight    0\n",
       "Viscera weight    0\n",
       "Shell weight      0\n",
       "Rings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df.select_dtypes(include=['object']).isnull().sum()\n",
    "abalone_df.select_dtypes(include=[np.number]).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55525529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding age column in the dataframe for classification. Age is classified based on the number of rings.\n",
    "#Rings 1-8 -->Age 1, denoting young\n",
    "# Rings 9-10 -->Age 2, denoting middle\n",
    "# Rings 11-29 -->Age 3, denoting old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac1b0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_race (row):\n",
    "    if row['Rings']>=1 and row['Rings']<=8:\n",
    "        return 1\n",
    "    elif row['Rings'] >=9 and row['Rings']<=10:\n",
    "        return 2\n",
    "    elif row['Rings']>=11 and row['Rings']<=29:\n",
    "        return 3\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6276b163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>2</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>1</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>1</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>1</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0       1   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       1   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       2   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       1   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       3   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    2   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    1   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    1   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    2   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    1   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera weight  Shell weight  Rings  Age  \n",
       "0             0.1010        0.1500     15    3  \n",
       "1             0.0485        0.0700      7    1  \n",
       "2             0.1415        0.2100      9    2  \n",
       "3             0.1140        0.1550     10    2  \n",
       "4             0.0395        0.0550      7    1  \n",
       "...              ...           ...    ...  ...  \n",
       "4172          0.2390        0.2490     11    3  \n",
       "4173          0.2145        0.2605     10    2  \n",
       "4174          0.2875        0.3080      9    2  \n",
       "4175          0.2610        0.2960     10    2  \n",
       "4176          0.3765        0.4950     12    3  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df['Age'] = abalone_df.apply(lambda _: '', axis=1)\n",
    "abalone_df['Age']=abalone_df.apply (lambda row: label_race (row),axis=1)\n",
    "# abalone_df.Sex = abalone_df.Sex.astype(float)\n",
    "abalone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7664c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4177 non-null   int64  \n",
      " 1   Length          4177 non-null   float64\n",
      " 2   Diameter        4177 non-null   float64\n",
      " 3   Height          4177 non-null   float64\n",
      " 4   Whole weight    4177 non-null   float64\n",
      " 5   Shucked weight  4177 non-null   float64\n",
      " 6   Viscera weight  4177 non-null   float64\n",
      " 7   Shell weight    4177 non-null   float64\n",
      " 8   Rings           4177 non-null   int64  \n",
      " 9   Age             4177 non-null   int64  \n",
      "dtypes: float64(7), int64(3)\n",
      "memory usage: 326.5 KB\n"
     ]
    }
   ],
   "source": [
    "abalone_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "661f71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response variable is age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ae02fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = abalone_df[['Age']]\n",
    "X = abalone_df.drop(['Age','Rings'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36be77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into 75% training and 25% test data using train_test_split\n",
    "\n",
    "# from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_validate as cv\n",
    "\n",
    "# X_train, y_train, X_test, y_test =train_test_split(X, y)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y) # splits 75%/25% by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4811cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_x:\n",
      "(3132, 8)\n",
      "train_df_y:\n",
      "(3132, 1)\n",
      "test_df_x:\n",
      "(1045, 8)\n",
      "test_df_y:\n",
      "(1045, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_df_x:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "print(\"train_df_y:\")\n",
    "print(train_y.shape)\n",
    "\n",
    "print(\"test_df_x:\")\n",
    "print(test_X.shape)\n",
    "\n",
    "print(\"test_df_y:\")\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82d1a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for x in range(len(testSet)):\n",
    "\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "\n",
    "            correct += 1\n",
    "\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be6a6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept is  [ 2.42021245 -1.10506645 -1.315146  ]\n",
      "Coefficient is  [[ 0.28096135 -1.48875905 -1.93005255 -1.4027539  -2.33373752  4.66152265\n",
      "  -0.84796968 -4.69964869]\n",
      " [-0.11703691  2.01882702  1.18868548  0.10818049 -0.78536182  1.42518176\n",
      "   1.25198571 -0.37094476]\n",
      " [-0.16392444 -0.53006797  0.74136707  1.2945734   3.11909933 -6.08670441\n",
      "  -0.40401603  5.07059345]]\n",
      "Accuracy of Logistic Regression is: 0.6564593301435406\n",
      "MAE:0.38181818181818183\n",
      "RMSE:0.6770326474710262\n",
      "Median Absolute Error:0.0\n",
      "Classification report for Test data LogisticRegression(multi_class='multinomial', solver='newton-cg'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.80      0.76       359\n",
      "           2       0.52      0.44      0.48       332\n",
      "           3       0.68      0.71      0.69       354\n",
      "\n",
      "    accuracy                           0.66      1045\n",
      "   macro avg       0.64      0.65      0.65      1045\n",
      "weighted avg       0.65      0.66      0.65      1045\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "#logistic regression\n",
    "log_reg = LogisticRegression(multi_class='multinomial',solver ='newton-cg')\n",
    "log_reg.fit(train_X, train_y)\n",
    "print (\"Intercept is \",log_reg.intercept_)\n",
    "print(\"Coefficient is \",log_reg.coef_)\n",
    "y_pred=log_reg.predict(test_X) \n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy of Logistic Regression is:\", accuracy_score(test_y, y_pred))\n",
    "\n",
    "#Mean Absolute Error \n",
    "mae=mean_absolute_error(test_y,y_pred);\n",
    "print(\"MAE:\"+str(mae))\n",
    "\n",
    "#RMSE \n",
    "rmse = math.sqrt(mean_squared_error(test_y,y_pred))\n",
    "print(\"RMSE:\"+str(rmse))\n",
    "\n",
    "#Median Absolute error\n",
    "Medae=median_absolute_error(test_y,y_pred)\n",
    "print(\"Median Absolute Error:\"+str(Medae)) \n",
    "\n",
    "#Classification Report\n",
    "print(\"Classification report for Test data %s:\\n%s\\n\\n\"\n",
    "     % (log_reg, metrics.classification_report(test_y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabe3ea",
   "metadata": {},
   "source": [
    "#### 5.\tCreate a neural network using pytorch to predict the same result as question 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a459a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 9)\n",
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    }
   ],
   "source": [
    "abalone_df = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone_df.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "abalone_df = pd.DataFrame(abalone_df, columns=abalone_df.columns)\n",
    "y = abalone_df.Rings\n",
    "\n",
    "print(abalone_df.shape)\n",
    "print(abalone_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "525fae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings   Age  \n",
       "0         0.150     15  16.5  \n",
       "1         0.070      7   8.5  \n",
       "2         0.210      9  10.5  \n",
       "3         0.155     10  11.5  \n",
       "4         0.055      7   8.5  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As Rings: +1.5 gives the age in years , So we will replace rings with age\n",
    "abalone_df['Age'] = abalone_df['Rings'] + 1.5\n",
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02aa8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the sex attribute.\n",
    "df_dummies = pd.get_dummies(abalone_df['Sex'], prefix = \"Sex_\") \n",
    "\n",
    "# Inserting dummy columns\n",
    "for column in df_dummies.columns:\n",
    "    abalone_df[column] = df_dummies[column]  # one-hot encoded columns are appended to the data frame\n",
    "    \n",
    "# Dropping the original column\n",
    "abalone_df = abalone_df.drop(columns = ['Sex'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f04f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight  Rings   Age  Sex__F  Sex__I  Sex__M  \n",
      "0           0.1500     15  16.5       0       0       1  \n",
      "1           0.0700      7   8.5       0       0       1  \n",
      "2           0.2100      9  10.5       1       0       0  \n",
      "3           0.1550     10  11.5       0       0       1  \n",
      "4           0.0550      7   8.5       0       1       0  \n",
      "...            ...    ...   ...     ...     ...     ...  \n",
      "4172        0.2490     11  12.5       1       0       0  \n",
      "4173        0.2605     10  11.5       0       0       1  \n",
      "4174        0.3080      9  10.5       0       0       1  \n",
      "4175        0.2960     10  11.5       1       0       0  \n",
      "4176        0.4950     12  13.5       0       0       1  \n",
      "\n",
      "[4177 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(abalone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae19f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = abalone_df.drop(['Rings','Age'], axis = 1)\n",
    "y = abalone_df.drop(['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight',\n",
    "              'Shell weight', 'Age','Sex__F','Sex__I','Sex__M'], axis = 1)\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# #Standardize the data\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a21b7ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_x:\n",
      "(2923, 10)\n",
      "train_df_y:\n",
      "(2923, 1)\n",
      "test_df_x:\n",
      "(1254, 10)\n",
      "test_df_y:\n",
      "(1254, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_df_x:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"train_df_y:\")\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"test_df_x:\")\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"test_df_y:\")\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c92a2e25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19860/3887716695.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F # Activation function\n",
    "\n",
    "# Create tensors \n",
    "X_train = torch.Tensor(X_train) \n",
    "X_test = torch.Tensor(X_test)\n",
    "\n",
    "y_train = torch.Tensor(y_train)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "# test_tensor = torch.Tensor(test.values)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#artificial neural network\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=10,hidden1=100,hidden2=100,out_features=2):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "#         self.layer_3_connection = nn.Linear(hidden2, hidden3)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.softmax(self.layer_2_connection(x))\n",
    "#         x = F.relu(self.layer_3_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "a09e3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69)\n",
    "\n",
    "#create instance of model\n",
    "ann = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "27ae34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "8b5ef49e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21100/1960002584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfinal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_train, y_pred)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss}')\n",
    "        \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() \n",
    "    optimizer.step() #perform one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d1c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predictions\n",
    "# y_pred = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i, data in enumerate(X_test):\n",
    "#         prediction = ann(data)\n",
    "#         y_pred.append(prediction.argmax()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb04b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import mean_squared_error as MSE\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# # Evaluate the test set RMSE\n",
    "# rmse_test = MSE(y_test, y_pred)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc903ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09788f85",
   "metadata": {},
   "outputs": [],
   "source": [
    " from collections import OrderedDict\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "('hidden_linear', nn.Linear(11, 100)),\n",
    "('hidden_activation', nn.Tanh()),\n",
    "('output_linear', nn.Linear(100, 7))\n",
    "]))\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, target_train, target_val, data_train, data_val):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        t_p_train = model(data_train)\n",
    "        loss_train = loss_fn(t_p_train, target_train)\n",
    "        \n",
    "        optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "        loss_train.backward() \n",
    "        optimizer.step() #perform one optimization step each epoch\n",
    "        \n",
    "        if epoch == 1 or epoch % 1000 ==0:\n",
    "            print(f'Epoch number: {epoch}, Training loss: {loss_train.item():.f},'\n",
    "                  f' Validation loss {loss_val.ite():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131be90",
   "metadata": {},
   "source": [
    "#### 6.\tCompare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52180812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa723286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
