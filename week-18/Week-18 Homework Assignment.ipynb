{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a8f4a5",
   "metadata": {},
   "source": [
    "# Week-18 Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94210127",
   "metadata": {},
   "source": [
    "#### 1.\tWhat is a neural network? What are the general steps required to build a neural network? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd3fe2",
   "metadata": {},
   "source": [
    "#### Neural network\n",
    "A large connected network which is passing the inputs(values) through hidden layers and there is some computation happening\n",
    "to get the desired output. speeding up the process with high efficiency is one of the advantage in artificial neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba328b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a94020",
   "metadata": {},
   "source": [
    "#### 2.\tGenerally, how do you check the performance of a neural network? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256139b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099d64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e9918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee97a468",
   "metadata": {},
   "source": [
    "#### 3.\tCreate a neural network using keras to predict the outcome of either of these datasets: \n",
    "\n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "\n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da918343",
   "metadata": {},
   "source": [
    "The common name for Abalone is sea snail. we can determine the age of the abalone by cutting the shell through the cone,\n",
    "stained and the rings are counted using the microscope. All these is a time consuming process that can be simplified \n",
    "using neural networks. Here, we can predict their age using physical measurements like length, height, weight and\n",
    "other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54164347",
   "metadata": {},
   "source": [
    "Lets import our Abalone dataset and some dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "eb31df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "74082566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset (Abalone dataset)\n",
    "target_url = (r\"A:\\launch_code_STL\\Final_Homework\\week-17\\abalone.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9487baa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 9)\n",
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    }
   ],
   "source": [
    "abalone_df = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone_df.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "\n",
    "print(abalone_df.shape)\n",
    "print(abalone_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e49bf3",
   "metadata": {},
   "source": [
    "The dataset contains 4177 samples and each sample has 9 features('Sex', 'Length', 'Diameter', 'Height', 'Whole weight', \n",
    "'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings') The Rings feature is the target variable and as given \n",
    "in the documentation, adding 1.5 to the ring attribute gives the age of the abalone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32ea79",
   "metadata": {},
   "source": [
    "###  Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43037a",
   "metadata": {},
   "source": [
    "#### Encoding the input columns\n",
    "\n",
    "Out of the 8 input columns, 'Sex' column is a categorical attribute, we need to perform one hot encoding, we use \n",
    "get_dummies() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "6c500948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the sex attribute.\n",
    "df_dummies = pd.get_dummies(abalone_df['Sex'], prefix = \"Sex_\") # drop_first parameter is set to True, this means\n",
    "                                                                           # that if there are n categories in the column,\n",
    "                                                                           # n-1 columns are returned instead of n.\n",
    "\n",
    "# Inserting dummy columns\n",
    "for column in df_dummies.columns:\n",
    "    abalone_df[column] = df_dummies[column]  # one-hot encoded columns are appended to the data frame\n",
    "    \n",
    "# Dropping the original column\n",
    "abalone_df = abalone_df.drop(columns = ['Sex'])     # original 'Sex' attribute column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e7e21724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight  Rings  Sex__F  Sex__I  Sex__M  \n",
      "0           0.1500     15       0       0       1  \n",
      "1           0.0700      7       0       0       1  \n",
      "2           0.2100      9       1       0       0  \n",
      "3           0.1550     10       0       0       1  \n",
      "4           0.0550      7       0       1       0  \n",
      "...            ...    ...     ...     ...     ...  \n",
      "4172        0.2490     11       1       0       0  \n",
      "4173        0.2605     10       0       0       1  \n",
      "4174        0.3080      9       0       0       1  \n",
      "4175        0.2960     10       1       0       0  \n",
      "4176        0.4950     12       0       0       1  \n",
      "\n",
      "[4177 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(abalone_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a5c7a",
   "metadata": {},
   "source": [
    "#### Encoding the output columns\n",
    "\n",
    "The attribute 'Rings' is with continuous values ranging from 1 to 29. we can split these into 3 categories â€” \n",
    "less than 10(young), between 10 and 20 (middle age), between 20 and 30(old).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "fa9ec6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rings_label(x):\n",
    "    if x<=10:\n",
    "        return 'young'\n",
    "    if x<=20:\n",
    "        return 'middle age'\n",
    "    if x<=30:\n",
    "        return 'old'\n",
    "    \n",
    "abalone_df['Rings'] = abalone_df['Rings'].apply(rings_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d9aa1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight       Rings  Sex__F  Sex__I  Sex__M  \n",
      "0           0.1500  middle age       0       0       1  \n",
      "1           0.0700       young       0       0       1  \n",
      "2           0.2100       young       1       0       0  \n",
      "3           0.1550       young       0       0       1  \n",
      "4           0.0550       young       0       1       0  \n",
      "...            ...         ...     ...     ...     ...  \n",
      "4172        0.2490  middle age       1       0       0  \n",
      "4173        0.2605       young       0       0       1  \n",
      "4174        0.3080       young       0       0       1  \n",
      "4175        0.2960       young       1       0       0  \n",
      "4176        0.4950  middle age       0       0       1  \n",
      "\n",
      "[4177 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(abalone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "6478143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the Rings attribute.\n",
    "df_dummies = pd.get_dummies(abalone_df['Rings'])\n",
    "\n",
    "# Inserting dummy columns\n",
    "for column in df_dummies.columns:\n",
    "    abalone_df[column] = df_dummies[column]\n",
    "    \n",
    "# Dropping the original column\n",
    "df = abalone_df.drop(columns = ['Rings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "95b15b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the input and output columns to separate the dataset in the later cells.\n",
    "\n",
    "input_columns = df.columns.tolist()\n",
    "input_columns.remove('young')\n",
    "input_columns.remove('middle age')\n",
    "input_columns.remove('old')\n",
    "\n",
    "output_columns = ['young', 'middle age', 'old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "4f0bdf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight  Sex__F  Sex__I  Sex__M  middle age  old  young  \n",
      "0           0.1500       0       0       1           1    0      0  \n",
      "1           0.0700       0       0       1           0    0      1  \n",
      "2           0.2100       1       0       0           0    0      1  \n",
      "3           0.1550       0       0       1           0    0      1  \n",
      "4           0.0550       0       1       0           0    0      1  \n",
      "...            ...     ...     ...     ...         ...  ...    ...  \n",
      "4172        0.2490       1       0       0           1    0      0  \n",
      "4173        0.2605       0       0       1           0    0      1  \n",
      "4174        0.3080       0       0       1           0    0      1  \n",
      "4175        0.2960       1       0       0           0    0      1  \n",
      "4176        0.4950       0       0       1           1    0      0  \n",
      "\n",
      "[4177 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "40278bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train, val and test set -- 80-10-10 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, an 80-20 split\n",
    "train_df, val_test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "# Then split the 20% into half\n",
    "val_df, test_df = train_test_split(val_test_df, test_size = 0.5)\n",
    "\n",
    "# Splitting into X (input) and y (output)\n",
    "\n",
    "X_train, y_train = np.array(train_df[input_columns]), np.array(train_df[output_columns])\n",
    "\n",
    "X_val, y_val = np.array(val_df[input_columns]), np.array(val_df[output_columns])\n",
    "\n",
    "X_test, y_test = np.array(test_df[input_columns]), np.array(test_df[output_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "75f8c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "Xtrain = sc.fit_transform(X_train)\n",
    "Xval = sc.transform(X_val)\n",
    "Xtest = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b0c2878a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3443 - mean_absolute_error: 0.3443 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598\n",
      "Epoch 2/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2370 - mean_absolute_error: 0.2370 - val_loss: 0.2376 - val_mean_absolute_error: 0.2376\n",
      "Epoch 3/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2298 - mean_absolute_error: 0.2298 - val_loss: 0.2357 - val_mean_absolute_error: 0.2357\n",
      "Epoch 4/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2287 - mean_absolute_error: 0.2287 - val_loss: 0.2351 - val_mean_absolute_error: 0.2351\n",
      "Epoch 5/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2284 - mean_absolute_error: 0.2284 - val_loss: 0.2349 - val_mean_absolute_error: 0.2349\n",
      "Epoch 6/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2282 - mean_absolute_error: 0.2282 - val_loss: 0.2347 - val_mean_absolute_error: 0.2347\n",
      "Epoch 7/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2281 - mean_absolute_error: 0.2281 - val_loss: 0.2346 - val_mean_absolute_error: 0.2346\n",
      "Epoch 8/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2280 - mean_absolute_error: 0.2280 - val_loss: 0.2346 - val_mean_absolute_error: 0.2346\n",
      "Epoch 9/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2280 - mean_absolute_error: 0.2280 - val_loss: 0.2346 - val_mean_absolute_error: 0.2346\n",
      "Epoch 10/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2280 - mean_absolute_error: 0.2280 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 11/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2280 - mean_absolute_error: 0.2280 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 12/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 13/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 14/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 15/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 16/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 17/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 18/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 19/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 20/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 21/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 22/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 23/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 24/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 25/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 26/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 27/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 28/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 29/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 30/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 31/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 32/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 33/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 34/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 35/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 36/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 37/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 38/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 39/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 40/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 41/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 42/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 43/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 44/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 45/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 46/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 47/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 48/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 49/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 50/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 51/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 52/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 53/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 54/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 55/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 56/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 57/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 58/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 59/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 60/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 61/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 62/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 63/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 64/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 65/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 66/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 67/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 68/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 69/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 70/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 71/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 72/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 73/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 74/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 75/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 76/256\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 77/256\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 0.2279 - mean_absolute_error: 0.2279 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import keras.callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(32, activation = 'relu', input_shape = X_train[0].shape),\n",
    "    layers.Dense(8, activation = 'relu'),\n",
    "    layers.Dense(3, activation = 'softmax')])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model.compile(optimizer = 'Adam', loss = 'mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "\n",
    "# model.compile(optimizer = 'Adam', loss = 'CategoricalCrossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 256, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2479e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2472 - mean_absolute_error: 0.2472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24720904231071472, 0.24720904231071472]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "22e1a9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 32)                320       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 611\n",
      "Trainable params: 611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary for number of parameters used in the algorithm\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818f2e5",
   "metadata": {},
   "source": [
    "#### 4.\tWrite another algorithm to predict the same result as the previous question using either KNN or logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "bba8cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 9)\n",
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    }
   ],
   "source": [
    "abalone_df = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone_df.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "# abalone_df = pd.DataFrame(abalone_df, columns=abalone_df.columns)\n",
    "# y = abalone_df.Rings\n",
    "\n",
    "print(abalone_df.shape)\n",
    "print(abalone_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "e53c5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dictionary = {'M': 1, 'F' : 2,'I':3}\n",
    "abalone_df['Sex'] = abalone_df['Sex'].apply(lambda x: sex_dictionary[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "26205293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex                 int64\n",
       "Length            float64\n",
       "Diameter          float64\n",
       "Height            float64\n",
       "Whole weight      float64\n",
       "Shucked weight    float64\n",
       "Viscera weight    float64\n",
       "Shell weight      float64\n",
       "Rings               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "f326ad3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Whole weight      0\n",
       "Shucked weight    0\n",
       "Viscera weight    0\n",
       "Shell weight      0\n",
       "Rings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df.select_dtypes(include=['object']).isnull().sum()\n",
    "abalone_df.select_dtypes(include=[np.number]).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "55525529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding age column in the dataframe for classification. Age is classified based on the number of rings.\n",
    "#Rings 1-8 -->Age 1, denoting young\n",
    "# Rings 9-10 -->Age 2, denoting middle\n",
    "# Rings 11-29 -->Age 3, denoting old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "ac1b0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_race (row):\n",
    "    if row['Rings']>=1 and row['Rings']<=8:\n",
    "        return 1\n",
    "    elif row['Rings'] >=9 and row['Rings']<=10:\n",
    "        return 2\n",
    "    elif row['Rings']>=11 and row['Rings']<=29:\n",
    "        return 3\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6276b163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>2</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>1</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>1</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>1</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0       1   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       1   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       2   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       1   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       3   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    2   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    1   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    1   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    2   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    1   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera weight  Shell weight  Rings  Age  \n",
       "0             0.1010        0.1500     15    3  \n",
       "1             0.0485        0.0700      7    1  \n",
       "2             0.1415        0.2100      9    2  \n",
       "3             0.1140        0.1550     10    2  \n",
       "4             0.0395        0.0550      7    1  \n",
       "...              ...           ...    ...  ...  \n",
       "4172          0.2390        0.2490     11    3  \n",
       "4173          0.2145        0.2605     10    2  \n",
       "4174          0.2875        0.3080      9    2  \n",
       "4175          0.2610        0.2960     10    2  \n",
       "4176          0.3765        0.4950     12    3  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df['Age'] = abalone_df.apply(lambda _: '', axis=1)\n",
    "abalone_df['Age']=abalone_df.apply (lambda row: label_race (row),axis=1)\n",
    "# abalone_df.Sex = abalone_df.Sex.astype(float)\n",
    "abalone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f7664c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             4177 non-null   int64  \n",
      " 1   Length          4177 non-null   float64\n",
      " 2   Diameter        4177 non-null   float64\n",
      " 3   Height          4177 non-null   float64\n",
      " 4   Whole weight    4177 non-null   float64\n",
      " 5   Shucked weight  4177 non-null   float64\n",
      " 6   Viscera weight  4177 non-null   float64\n",
      " 7   Shell weight    4177 non-null   float64\n",
      " 8   Rings           4177 non-null   int64  \n",
      " 9   Age             4177 non-null   int64  \n",
      "dtypes: float64(7), int64(3)\n",
      "memory usage: 326.5 KB\n"
     ]
    }
   ],
   "source": [
    "abalone_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "661f71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response variable is age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "2ae02fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = abalone_df[['Age']]\n",
    "X = abalone_df.drop(['Age','Rings'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "36be77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the dataset into 75% training and 25% test data using train_test_split\n",
    "\n",
    "# from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_validate as cv\n",
    "\n",
    "# X_train, y_train, X_test, y_test =train_test_split(X, y)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y) # splits 75%/25% by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "4811cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_x:\n",
      "(3132, 8)\n",
      "train_df_y:\n",
      "(3132, 1)\n",
      "test_df_x:\n",
      "(1045, 8)\n",
      "test_df_y:\n",
      "(1045, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_df_x:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "print(\"train_df_y:\")\n",
    "print(train_y.shape)\n",
    "\n",
    "print(\"test_df_x:\")\n",
    "print(test_X.shape)\n",
    "\n",
    "print(\"test_df_y:\")\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "82d1a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for x in range(len(testSet)):\n",
    "\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "\n",
    "            correct += 1\n",
    "\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "be6a6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept is  [ 2.49975834 -1.00850406 -1.49125428]\n",
      "Coefficient is  [[ 0.32348155 -1.54749461 -2.08639723 -1.7553194  -2.35599186  4.33355641\n",
      "  -0.6671625  -4.43501068]\n",
      " [-0.14213881  1.86873305  1.45182587  0.0130799  -0.96763201  1.91531126\n",
      "   1.07611901 -0.47554634]\n",
      " [-0.18134273 -0.32123844  0.63457137  1.7422395   3.32362387 -6.24886767\n",
      "  -0.40895652  4.91055702]]\n",
      "Accuracy of Logistic Regression is: 0.6239234449760765\n",
      "MAE:0.43732057416267944\n",
      "RMSE:0.7482035902347646\n",
      "Median Absolute Error:0.0\n",
      "Classification report for Test data LogisticRegression(multi_class='multinomial', solver='newton-cg'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.76      0.73       371\n",
      "           2       0.49      0.44      0.46       322\n",
      "           3       0.64      0.65      0.65       352\n",
      "\n",
      "    accuracy                           0.62      1045\n",
      "   macro avg       0.61      0.62      0.61      1045\n",
      "weighted avg       0.62      0.62      0.62      1045\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "#logistic regression\n",
    "log_reg = LogisticRegression(multi_class='multinomial',solver ='newton-cg')\n",
    "log_reg.fit(train_X, train_y)\n",
    "print (\"Intercept is \",log_reg.intercept_)\n",
    "print(\"Coefficient is \",log_reg.coef_)\n",
    "y_pred=log_reg.predict(test_X) \n",
    "\n",
    "# Accuracy Score\n",
    "print(\"Accuracy of Logistic Regression is:\", accuracy_score(test_y, y_pred))\n",
    "\n",
    "#Mean Absolute Error \n",
    "mae=mean_absolute_error(test_y,y_pred);\n",
    "print(\"MAE:\"+str(mae))\n",
    "\n",
    "#RMSE \n",
    "rmse = math.sqrt(mean_squared_error(test_y,y_pred))\n",
    "print(\"RMSE:\"+str(rmse))\n",
    "\n",
    "#Median Absolute error\n",
    "Medae=median_absolute_error(test_y,y_pred)\n",
    "print(\"Median Absolute Error:\"+str(Medae)) \n",
    "\n",
    "#Classification Report\n",
    "print(\"Classification report for Test data %s:\\n%s\\n\\n\"\n",
    "     % (log_reg, metrics.classification_report(test_y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabe3ea",
   "metadata": {},
   "source": [
    "#### 5.\tCreate a neural network using pytorch to predict the same result as question 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "5a459a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4177, 9)\n",
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    }
   ],
   "source": [
    "abalone_df = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "abalone_df.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "abalone_df = pd.DataFrame(abalone_df, columns=abalone_df.columns)\n",
    "y = abalone_df.Rings\n",
    "\n",
    "print(abalone_df.shape)\n",
    "print(abalone_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "525fae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings   Age  \n",
       "0         0.150     15  16.5  \n",
       "1         0.070      7   8.5  \n",
       "2         0.210      9  10.5  \n",
       "3         0.155     10  11.5  \n",
       "4         0.055      7   8.5  "
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As Rings: +1.5 gives the age in years , So we will replace rings with age\n",
    "abalone_df['Age'] = abalone_df['Rings'] + 1.5\n",
    "\n",
    "#  Now we will drop Rings\n",
    "# abalone_df.drop('Rings', axis=1, inplace=True)\n",
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "02aa8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the sex attribute.\n",
    "df_dummies = pd.get_dummies(abalone_df['Sex'], prefix = \"Sex_\") # drop_first parameter is set to True, this means\n",
    "                                                                           # that if there are n categories in the column,\n",
    "                                                                           # n-1 columns are returned instead of n.\n",
    "\n",
    "# Inserting dummy columns\n",
    "for column in df_dummies.columns:\n",
    "    abalone_df[column] = df_dummies[column]  # one-hot encoded columns are appended to the data frame\n",
    "    \n",
    "# Dropping the original column\n",
    "abalone_df = abalone_df.drop(columns = ['Sex'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "5f04f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight  Rings   Age  Sex__F  Sex__I  Sex__M  \n",
      "0           0.1500     15  16.5       0       0       1  \n",
      "1           0.0700      7   8.5       0       0       1  \n",
      "2           0.2100      9  10.5       1       0       0  \n",
      "3           0.1550     10  11.5       0       0       1  \n",
      "4           0.0550      7   8.5       0       1       0  \n",
      "...            ...    ...   ...     ...     ...     ...  \n",
      "4172        0.2490     11  12.5       1       0       0  \n",
      "4173        0.2605     10  11.5       0       0       1  \n",
      "4174        0.3080      9  10.5       0       0       1  \n",
      "4175        0.2960     10  11.5       1       0       0  \n",
      "4176        0.4950     12  13.5       0       0       1  \n",
      "\n",
      "[4177 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(abalone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "ae19f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = abalone_df.drop(['Rings','Age'], axis = 1)\n",
    "y = abalone_df.drop(['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight',\n",
    "              'Shell weight', 'Age','Sex__F','Sex__I','Sex__M'], axis = 1)\n",
    "\n",
    "# y[columnn] = pd.DataFrame(y)\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# #Standardize the data\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "6bf877a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = abalone_df.drop(['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight',\n",
    "#               'Shell weight', 'Rings','Sex__F','Sex__I','Sex__M'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "3c3d61d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Rings\n",
      "0        15\n",
      "1         7\n",
      "2         9\n",
      "3        10\n",
      "4         7\n",
      "...     ...\n",
      "4172     11\n",
      "4173     10\n",
      "4174      9\n",
      "4175     10\n",
      "4176     12\n",
      "\n",
      "[4177 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "a21b7ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_x:\n",
      "(2923, 10)\n",
      "train_df_y:\n",
      "(2923, 1)\n",
      "test_df_x:\n",
      "(1254, 10)\n",
      "test_df_y:\n",
      "(1254, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_df_x:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"train_df_y:\")\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"test_df_x:\")\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"test_df_y:\")\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "c92a2e25",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got builtin_function_or_method)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21100/1032724562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Create tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): data must be a sequence (got builtin_function_or_method)"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F # Activation function\n",
    "\n",
    "# Create tensors \n",
    "X_train = torch.Tensor(X_train) \n",
    "X_test = torch.Tensor(X_test)\n",
    "\n",
    "y_train = torch.Tensor(y_train)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "# test_tensor = torch.Tensor(test.values)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "d1e3543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#artificial neural network\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=10,hidden1=100,hidden2=100,out_features=2):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "#         self.layer_3_connection = nn.Linear(hidden2, hidden3)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.softmax(self.layer_2_connection(x))\n",
    "#         x = F.relu(self.layer_3_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "a09e3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69)\n",
    "\n",
    "#create instance of model\n",
    "ann = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "27ae34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "8b5ef49e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21100/1960002584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfinal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_train, y_pred)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss}')\n",
    "        \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() \n",
    "    optimizer.step() #perform one optimization step each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "10d1c813",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x10 and 9x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21100/1041219137.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21100/2712894272.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#apply activation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_1_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_2_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#         x = F.relu(self.layer_3_connection(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x10 and 9x100)"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = ann(data)\n",
    "        y_pred.append(prediction.argmax()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eb04b0cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (3!=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21100/4020187380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Evaluate the test set RMSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrmse_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \"\"\"\n\u001b[1;32m--> 423\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    101\u001b[0m             \"y_true and y_pred have different number of output ({0}!={1})\".format(\n\u001b[0;32m    102\u001b[0m                 \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (3!=1)"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f799a18f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21100/2868965168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2074\u001b[0m     \"\"\"\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2076\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc903ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "168cb51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(target_url,header=None, prefix=\"V\")\n",
    "df.columns = ['Sex', 'Length', 'Diameter', 'Height',\n",
    "                   'Whole weight', 'Shucked weight',\n",
    "                   'Viscera weight', 'Shell weight', 'Rings']\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4e9846c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df[\"M\"] = np.nan\n",
    "df[\"F\"] = np.nan\n",
    "df[\"I\"] = np.nan\n",
    "columnName='Sex'\n",
    "for i in range (len(df[columnName])):\n",
    "    if df[columnName][i]=='M':\n",
    "        df['M'][i]=1\n",
    "        df['F'][i]=0\n",
    "        df['I'][i]=0\n",
    "    elif df[columnName][i]=='F':\n",
    "        df['M'][i]=0\n",
    "        df['F'][i]=1\n",
    "        df['I'][i]=0\n",
    "    elif df[columnName][i]=='I' :\n",
    "        df['M'][i]=0\n",
    "        df['F'][i]=0\n",
    "        df['I'][i]=1\n",
    "df=df.drop(['Sex'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "12982fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "...      ...       ...     ...           ...             ...             ...   \n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell weight  Rings    M    F    I  \n",
      "0           0.1500     15  1.0  0.0  0.0  \n",
      "1           0.0700      7  1.0  0.0  0.0  \n",
      "2           0.2100      9  0.0  1.0  0.0  \n",
      "3           0.1550     10  1.0  0.0  0.0  \n",
      "4           0.0550      7  0.0  0.0  1.0  \n",
      "...            ...    ...  ...  ...  ...  \n",
      "4172        0.2490     11  0.0  1.0  0.0  \n",
      "4173        0.2605     10  1.0  0.0  0.0  \n",
      "4174        0.3080      9  1.0  0.0  0.0  \n",
      "4175        0.2960     10  0.0  1.0  0.0  \n",
      "4176        0.4950     12  1.0  0.0  0.0  \n",
      "\n",
      "[4177 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "77ee08c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 256)               2816      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,449\n",
      "Trainable params: 200,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 4.9911 - mean_absolute_error: 4.9911\n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.8700 - mean_absolute_error: 1.8700\n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7582 - mean_absolute_error: 1.7582\n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.7265 - mean_absolute_error: 1.7265\n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.6910 - mean_absolute_error: 1.6910\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6629 - mean_absolute_error: 1.6629\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(10,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.summary()\n",
    "\n",
    "# early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# model.compile(optimizer = 'Adam', loss = 'CategoricalCrossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 256, callbacks = [early_stopping_monitor])\n",
    "\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "history = model.fit(x_train,y_train,batch_size=100,epochs=5,verbose=1)\n",
    "test=model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755089fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a1b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067d69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061da2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6142c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e648f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472aea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568be883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36d790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09788f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8131be90",
   "metadata": {},
   "source": [
    "#### 6.\tCompare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52180812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa723286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
