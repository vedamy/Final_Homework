{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a420831",
   "metadata": {},
   "source": [
    "# Week-19 Homework Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a87504",
   "metadata": {},
   "source": [
    "1.\tCreate a study guide for all the supervised learning models we have gone over. Include information about how the algorithms work, how they are evaluated, and any other information you deem necessary. Use your own words. Do NOT copy mine or that of articles we have read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb825bde",
   "metadata": {},
   "source": [
    "#### supervised learning models:\n",
    "With supervised learning task, we can generate a model or predict an output based on input values.\n",
    " In machine learning models the output of the model is typically called a label, target variable, or response variable or dependent variable.\n",
    " The inputs into the model are called features or predictors or independent variable.\n",
    "\n",
    "The algorithm \"learns\" the optimal model by studying a training set of data that consists of several obsevations, \n",
    "or instances, each of which contains values for both features and its labels.here, the supervised learning algorithm acts as\n",
    "a function that takes training data as input and produces a model as its output.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132af0f0",
   "metadata": {},
   "source": [
    "The most popular Python library for machine learning is the Scikit-Learn (sklearn) package. Scikit-Learn provides functions for creating supervised learning models, as well as for performing unsupervised learning tasks,also provides tools for working and preparing data in creating models.\n",
    "scikit-learn makes it very easy to try different models, since the Train-Test-Split/Instantiate/Fit/Predict pattern applies to all the classifiers and regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c36c9d",
   "metadata": {},
   "source": [
    "Supervised learning models are divided into Classification and Regression problems based on whether the target values are\n",
    "continuous or categorical.\n",
    "Classification, when the target values are discrete classes For example, Predicting whether the loan is at 'high risk' or \n",
    "'low risk'. In class example like predicting the patient as diabetic or not diabetic.\n",
    "\n",
    "Regression, when the target values are continuous, real numbers. For example, Predicting a credit score, predicting the sale\n",
    "price of a home.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15dfedd",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors(KNN)\n",
    "K-Nearest Neighbors(KNN) is a simple algorithm, used to predict the label of any data point by looking at the K. \n",
    "'K' in KNN is a parameter that refers to the number of nearset neighbors to include in the majority voting process. It is \n",
    "mostly used for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa07c8d",
   "metadata": {},
   "source": [
    "steps involved are:\n",
    "1. import all the necessary libraries from scikit-learn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "2. Instantiate the model, and set the number of neighbors\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=?)\n",
    "\n",
    "3. Fit the model to the training set, the labeled data\n",
    "\n",
    "knn.fit()\n",
    "\n",
    "4. Predict the label of an unlabeled data point(new data)\n",
    "\n",
    "knn.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a268fc",
   "metadata": {},
   "source": [
    "After prediction we need to test the model performance, to measure its performance we need a metric.\n",
    "Generally in classification problems we use accuracy as a performance metric.\n",
    "The classifier is trained on training set, generally we use train_test_split to split the data into training set and \n",
    "test set and then predictions are made on the test set and then compared with the known labels.\n",
    "The accuracy of the predictions is then computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59982a",
   "metadata": {},
   "source": [
    "#### Regression: \n",
    "In regression tasks, the target value is a continuously varying variable, like the price of a house.\n",
    "\n",
    "#### Linear Regression\n",
    "A linear regression model uses the features to generate predictions for the countinous/real-valued label. \n",
    "The model parameters are calculated by a learning algorithm to generate the model that provides the best fit for the given\n",
    "data. The learning algorithm measures the quality of the fit using the sum of squared errors loss function.\n",
    "\n",
    "1.To start with, we need to create features and target variables in distinct arrays, X and y. \n",
    "Using the .values attribute returns numpy arrays or using .to_numpy.\n",
    "\n",
    "2. We will now split the dataset into training and test sets, using an 80/20 split.\n",
    "\n",
    "3.Instantiate sklearn.linear_model.LinearRegression\n",
    "\n",
    "4.Fit the model by passing in the data and target.\n",
    "\n",
    "5.The trained model will contain two new attributes: intercept_ and coef_.\n",
    "The intercept_ attribute contains the optimal value of the fitted model and coef_ attribute contains a list of values of \n",
    "other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119de452",
   "metadata": {},
   "source": [
    "For classification models, score() returns the model's accuracy on the provided dataset.\n",
    "For regression models, score() returns the model's r-squared score, as calculated on the provided dataset.\n",
    "The r-squared score is a number between 0 and 1 that can be interpretted as the proportion of the variance of the response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3290572",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "Cross-validation is an important step in evaluating a model. It maximizes the amount of data that is used to train \n",
    "the model, the model is trained, and also tested on that data.\n",
    "\n",
    "we use scikit-learn's cross-validation, import cross_val_score from sklearn.model_selection.\n",
    "We do this by splitting the dataset into groups, or folds. As the dataset is split into 5 folds, \n",
    "this process is called 5-fold cross validation, if k-folds are used it is called k-fold CV.\n",
    "while using cross-validation, it is important to remember that if we use more folds, the more computationally expensive\n",
    "it will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0bd82",
   "metadata": {},
   "source": [
    "#### To test how good your model is?\n",
    "Accuracy is not useful in all the cases, particularly when dealing with class imbalance problems. For example,\n",
    "in spam detection where  99% of emails are real and only 1% are SPAM. There comes confusion_matrix into picture \n",
    "which gives the summary of predictive performance, True Positive, True Negative, False Negative, False Positive.\n",
    "Also, there are several other important metrics we can easily calculate from the confusion matrix.\n",
    "Precision, which is the number of true positives, divided by the total number to true positives and false positives.\n",
    "Recall, which is the number of true positives, divided by the total number of true positives and false negatives.\n",
    "Recall is also called sensitivity, or true positive rate.\n",
    "\n",
    "To evaluate the performance of binary classifiers, we use confusion matrix and generate a classification report.\n",
    "Import classification_report and confusion_matrix from sklearn.metrics. Then, create training and test sets, instantiate\n",
    "the model, then fit the model on the training set and predict the labels on the test set. Lastly, compute and print the\n",
    "confusion matrix and classification report using the confusion_matrix() and classification_report() functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a812575",
   "metadata": {},
   "source": [
    "#### Logistic regression \n",
    "Logistic regression is a linear classification method based on probabilty. It can be used in multi-class\n",
    "classification problems, as well as in binary clasiffication problems.\n",
    "\n",
    "1.We use the LogisticRegression class from Scikit-Learn to create the classification model, will start with extracting the \n",
    "feature and label arrays from the dataset, Before creating the model, we can roughly ckeck the probability of actual values\n",
    "using numpy.mean() function.\n",
    "\n",
    "2.Next split the data into training and test sets, now we use Scikit-Learn to create our logistic regression classifier and\n",
    "then print the parameters(intercept_ and coef_) for our optimal model.\n",
    "\n",
    "3.Then, model's score() method to used to calculate the accuracy on the training and test sets.\n",
    "\n",
    "4.Next, to generate predictions will use the predict() method.\n",
    "\n",
    "5.we will use predict_proba to generate probability estimates for each observations.\n",
    "\n",
    "6.Fnally, compute and print the confusion matrix and classification report for the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f7607",
   "metadata": {},
   "source": [
    "To evaluate the model performance we have ROC curve. It is a way to visually evaluate model performance. After building the logistic regression model, we try to evaluate its performance by plotting an ROC curve. This can be done using the .predict_proba() method.\n",
    "\n",
    "ROC(Receiver Operating Characteristic)curve is an evaluation metric for binary classification problems, created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various thresholds. It shows the trade-off between sensitivity (or TPR) and specificity (1 – FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba385f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters that needs to be specified before fitting a model, are called hyperparameters.\n",
    "By Choosing the correct hyperparameters we can build a successful model.\n",
    "\n",
    "When fitting different values of hypterparameter, it is better to use cross-validation along with train_test_split to avoid overfitting of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bc9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e245f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4e94318",
   "metadata": {},
   "source": [
    "#### Data Preprocessing steps:\n",
    "\n",
    "1. Handle missing data : drop or fill NaNs\n",
    "2. Cleaning Datatypes for all features\n",
    "3. Processing Categorical features to numerical values\n",
    "4. Feature Engineering\n",
    "5. Standardizing or Normalizing\n",
    "6. Removing redundant or related features\n",
    "7. Stratified Sampling / PCA (Dimensionality reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb6cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32bcf7bd",
   "metadata": {},
   "source": [
    "2.\tDo the same as question 1 except for unsupervised learning models. Something that is necessary for many models is determining number, so specify how you determine the number of clusters for example. Apply this concept to any other algorithms it is relevant for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8d930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf719ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9175a77",
   "metadata": {},
   "source": [
    "3.\tPreprocess the customer data https://www.kaggle.com/carrie1/ecommerce-data . How are you handling nulls? What process(es) are you using to encode and normalize the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b8b6722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d598166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541909, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"A:\\launch_code_STL\\Final_Homework\\week-19\\data.csv\", sep=\",\", encoding=\"ISO-8859-1\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebabcb",
   "metadata": {},
   "source": [
    "when we import the data in csv format, we get different characters in the data that's when we should be using encoding.\n",
    "In this dataset encoding is used to convert string into byte string. so, to be able to pass non-ascii data, we are using \n",
    "encoding=\"ISO-8859-1\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "08924589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093cc397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
